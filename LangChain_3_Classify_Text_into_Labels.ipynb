{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7YpG1agsHOWEbTMVUQQ6q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sampathk-hps/langchain-fundamentals-colab/blob/main/LangChain_3_Classify_Text_into_Labels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tagging means labeling a document with classes such as:\n",
        "\n",
        "* Sentiment\n",
        "* Language\n",
        "* Style (formal, informal etc.)\n",
        "* Covered topics\n",
        "* Political tendency"
      ],
      "metadata": {
        "id": "KcbUx7134MRx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tagging has a few components:\n",
        "\n",
        "1. function: Like extraction, tagging uses functions to specify how the model should tag a document\n",
        "2. schema: defines how we want to tag the document"
      ],
      "metadata": {
        "id": "aGOmBKJI4aDl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3SFGAtjf3EnE",
        "outputId": "29a1267e-1c3d-46f6-e6a1-e97e81ba16d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (0.3.76)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-0.3.77-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.4.28)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (2.11.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.3.1)\n",
            "Downloading langchain_core-0.3.77-py3-none-any.whl (449 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.5/449.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-core\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.76\n",
            "    Uninstalling langchain-core-0.3.76:\n",
            "      Successfully uninstalled langchain-core-0.3.76\n",
            "Successfully installed langchain-core-0.3.77\n"
          ]
        }
      ],
      "source": [
        "%pip install -U langchain-core"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-perplexity"
      ],
      "metadata": {
        "id": "v-Kmw-jK40RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"PERPLEXITY_API_KEY\"):\n",
        "    os.environ[\"PERPLEXITY_API_KEY\"] = getpass.getpass(\"Perplexity API Key:\")\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "llm = init_chat_model(model='sonar', model_provider='perplexity', )"
      ],
      "metadata": {
        "collapsed": true,
        "id": "H3RlKUQ6454O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa87c4f7"
      },
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "# Set the OPENAI_API_KEY environment variable for Perplexity\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Perplexity API Key:\")\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "# Initialize the Perplexity chat model\n",
        "llm = init_chat_model(model='sonar', model_provider='perplexity')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "# from pydantic import BaseModel, Field: Imports BaseModel and Field from Pydantic, which are used to define the structure (schema) of the desired output.\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "tagging_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "Extract the desired information from the following passage.\n",
        "\n",
        "Only extract the properties mentioned in the 'Classification' function.\n",
        "\n",
        "Passage:\n",
        "{input}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# class Classification(BaseModel): ...: Defines the Pydantic model Classification. This acts as the schema, specifying the expected fields (sentiment, aggressiveness, language) and their data types and descriptions.\n",
        "class Classification(BaseModel):\n",
        "    sentiment: str = Field(description=\"The sentiment of the text\")\n",
        "    aggressiveness: int = Field(\n",
        "        description=\"How aggressive the text is on a scale from 1 to 10\"\n",
        "    )\n",
        "    language: str = Field(description=\"The language the text is written in\")\n",
        "\n",
        "# Structured LLM: It takes the initialized language model (llm) and wraps it with the with_structured_output method. This method tells the language model to format its output according to the Classification Pydantic model.\n",
        "structured_llm = llm.with_structured_output(Classification)\n"
      ],
      "metadata": {
        "id": "pGPMoqxf66ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = \"This is the best pizza i have ever had. Toppings were so perfect, i loved it!\"\n",
        "prompt = tagging_prompt.invoke({\"input\": inp})\n",
        "response = structured_llm.invoke(prompt)\n",
        "\n",
        "# response\n",
        "response.model_dump()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67cJFHSb7o--",
        "outputId": "38040935-5cca-4540-ad6d-af34fa01999e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentiment': 'positive', 'aggressiveness': 0, 'language': 'english'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finer control"
      ],
      "metadata": {
        "id": "XNE7ueclB9w0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Careful schema definition gives us more control over the model's output.\n",
        "\n",
        "Specifically, we can define:\n",
        "\n",
        "1. Possible values for each property\n",
        "2. Description to make sure that the model understands the property\n",
        "3. Required properties to be returned"
      ],
      "metadata": {
        "id": "BJDDEulMCDDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Classification(BaseModel):\n",
        "    sentiment: str = Field(..., enum=[\"happy\", \"neutral\", \"sad\"])\n",
        "    aggressiveness: int = Field(\n",
        "        ...,\n",
        "        description=\"describes how aggressive the statement is, the higher the number the more aggressive\",\n",
        "        enum=[1, 2, 3, 4, 5],\n",
        "    )\n",
        "    language: str = Field(\n",
        "        ..., description=\"The language the text is written in\", enum=[\"spanish\", \"english\", \"french\", \"german\", \"italian\"]\n",
        "    )\n",
        "\n",
        "# Structured LLM\n",
        "structured_llm = llm.with_structured_output(Classification)"
      ],
      "metadata": {
        "id": "X7QtIm1iB-l0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = \"This is the best pizza i have ever had. Toppings were so perfect, i loved it!\"\n",
        "prompt = tagging_prompt.invoke({\"input\": inp})\n",
        "response = structured_llm.invoke(prompt)\n",
        "\n",
        "# response\n",
        "response.model_dump()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdG3ousJCryW",
        "outputId": "ae8f499b-e063-4ff6-f9a7-8904c73a04d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentiment': 'happy', 'aggressiveness': 1, 'language': 'english'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp = \"Estoy muy enojado con vos! Te voy a dar tu merecido!\"\n",
        "prompt = tagging_prompt.invoke({\"input\": inp})\n",
        "structured_llm.invoke(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RoQMl3bDG1E",
        "outputId": "c06d7e39-61f0-4dec-c13c-adaf361348a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classification(sentiment='neutral', aggressiveness=5, language='spanish')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}